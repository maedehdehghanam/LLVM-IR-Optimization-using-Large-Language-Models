# LLVM Intermediate Representation Optimization Using LLMs

## Description

This project focuses on optimizing LLVM intermediate representation (IR) using large language models (LLMs). The goal is to leverage the capabilities of LLMs to enhance the performance and efficiency of code represented in LLVM IR.

## Dataset
The codes used in this project are sourced from the **Exebench** and **ComPile** datasets. These codes have been converted to LLVM-IR and loop-optimized for further processing.

- **Dataset URL**: [[https://huggingface.co/datasets/maedehm02/llvm-ir-loop-optimized/tree/main](https://huggingface.co/datasets/maedehm02/llvm-ir-loop-optimized)](#)
- **Exebench Dataset**: [[Link to Exebench](https://huggingface.co/datasets/jordiae/exebench/tree/main)](#)
- **ComPile Dataset**: [[Link to ComPile](https://huggingface.co/datasets/llvm-ml/ComPile/commit/0c160390f06b3657d4d404a3a8d502ea4aeb3c0b)](#)




## Models

- **Code-gemma**: [[Lmaedehm02/code-gemma-Code-Instruct-Finetuned](https://huggingface.co/maedehm02/code-gemma-Code-Instruct-Finetune-test/commit/00b94e506d27f24e21e991626c80d64e0971b8c7)](#)
- **Llama 3**: [[maedehm02/Llama3-Code-Instruct-Finetuned](https://huggingface.co/maedehm02/LLama3-Code-Instruct-Finetune-test/commit/4bcaa16ce9063225cc66fe46695185c4acfee725)](#)
- **Code-Llama**: [[maedehm02/code-llama-Code-Instruct-Finetuned](https://huggingface.co/maedehm02/code-llama-Code-Instruct-Finetune-test/commit/775920a5ab7261955a907ba473cf869d6b64c975)](#)
